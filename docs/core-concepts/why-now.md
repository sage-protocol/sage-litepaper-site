# Why Now?

AI models evolve weekly; agent instructions rarely keep pace. Agent instructions and prompt libraries are still scattered across chats, docs, and private repos. As models shift, even well-tested agent instructions drift out of sync, and communities lose the ability to coordinate their agent fleets. Sage focuses on four persistent gaps:

1.  **No Shared Memory for Agents**  
    Everyone forks ad hoc copies of their agent instructions; there’s no governed, tamper-evident version that humans and agents can trust together.

2.  **Static Instructions Fall Behind**  
    Markets, models, and tooling evolve weekly. Yesterday’s prompts quietly break, and orchestration stalls without a governed path to ship updates.

3.  **Contributors Lose Attribution**  
    Reuse happens without provenance or revenue share, so the people training the network rarely see upside.

4.  **No Compounding Incentive Loop**  
    Communities lack a transparent way to pool funds, reward experiments, and reinvest the learnings so the collective intelligence plateaus.

> Sage exists to turn community knowledge into governed, composable intelligence that compounds.

---
